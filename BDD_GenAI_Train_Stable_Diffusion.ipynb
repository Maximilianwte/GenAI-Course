{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNWmuDdHLt9U4PmCiFnnR8d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Maximilianwte/GenAI-Course/blob/main/BDD_GenAI_Train_Stable_Diffusion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VrRl5CStNQC8"
      },
      "outputs": [],
      "source": [
        "!wget -q https://github.com/ShivamShrirao/diffusers/raw/main/examples/dreambooth/train_dreambooth.py\n",
        "!wget -q https://github.com/ShivamShrirao/diffusers/raw/main/scripts/convert_diffusers_to_original_stable_diffusion.py\n",
        "!pip install -qq git+https://github.com/huggingface/diffusers.git\n",
        "!wget -q https://github.com/huggingface/diffusers/raw/main/examples/dreambooth/train_dreambooth_lora.py\n",
        "%pip install -qq -U --pre triton\n",
        "%pip install -qq accelerate transformers ftfy bitsandbytes==0.35.0 gradio natsort safetensors xformers\n",
        "!accelerate config default\n",
        "import os\n",
        "from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler\n",
        "import torch\n",
        "from torch import autocast\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"runwayml/stable-diffusion-v1-5\"\n",
        "OUTPUT_DIR = \"/content/Test_Model\"\n",
        "!mkdir -p $OUTPUT_DIR"
      ],
      "metadata": {
        "id": "jj90pnCVNgcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate launch train_dreambooth.py \\\n",
        "  --pretrained_model_name_or_path=$MODEL_NAME \\\n",
        "  --pretrained_vae_name_or_path=\"stabilityai/sd-vae-ft-mse\" \\\n",
        "  --output_dir=$OUTPUT_DIR \\\n",
        "  --instance_data_dir='/content/XX' \\\n",
        "  --instance_prompt='xyzobject' \\\n",
        "  --seed=1 \\\n",
        "  --resolution=512 \\\n",
        "  --train_batch_size=1 \\\n",
        "  --train_text_encoder \\\n",
        "  --mixed_precision=\"fp16\" \\\n",
        "  --use_8bit_adam \\\n",
        "  --gradient_accumulation_steps=1 \\\n",
        "  --learning_rate=1e-6 \\\n",
        "  --lr_scheduler=\"constant\" \\\n",
        "  --lr_warmup_steps=0 \\\n",
        "  --with_prior_preservation --prior_loss_weight=1.0 \\\n",
        "  --num_class_images=0 \\\n",
        "  --sample_batch_size=2 \\\n",
        "  --max_train_steps=3000 \\\n",
        "  --save_min_steps=2000 \\\n",
        "  --save_interval=250"
      ],
      "metadata": {
        "id": "_jIw1VcfNhlW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = StableDiffusionPipeline.from_pretrained(OUTPUT_DIR, torch_dtype=torch.float16).to(\"cuda\")\n",
        "pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
        "g_cuda = torch.Generator(device='cuda')"
      ],
      "metadata": {
        "id": "psCZz1v-NpLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"xyzobject\"\n",
        "negative_prompt = \"\"\n",
        "\n",
        "\n",
        "seed = np.random.randint(1, 1000)\n",
        "g_cuda.manual_seed(seed)\n",
        "guidance_scale = 7\n",
        "with autocast(\"cuda\"), torch.inference_mode():\n",
        "    images = pipe(prompt, negative_prompt=negative_prompt, num_images_per_prompt=1, height=512, width=512, num_inference_steps=60, guidance_scale=guidance_scale, generator=g_cuda).images\n",
        "\n",
        "images[0]"
      ],
      "metadata": {
        "id": "ec0kQ0yGNrAB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}